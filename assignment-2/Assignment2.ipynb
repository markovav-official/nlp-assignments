{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIgM6C9HYUhm"
      },
      "source": [
        "# Context-sensitive Spelling Correction\n",
        "\n",
        "The goal of the assignment is to implement context-sensitive spelling correction. The input of the code will be a set of text lines and the output will be the same lines with spelling mistakes fixed.\n",
        "\n",
        "Submit the solution of the assignment to Moodle as a link to your GitHub repository containing this notebook.\n",
        "\n",
        "Useful links:\n",
        "- [Norvig's solution](https://norvig.com/spell-correct.html)\n",
        "- [Norvig's dataset](https://norvig.com/big.txt)\n",
        "- [Ngrams data](https://www.ngrams.info/download_coca.asp)\n",
        "\n",
        "Grading:\n",
        "- 60 points - Implement spelling correction\n",
        "- 20 points - Justify your decisions\n",
        "- 20 points - Evaluate on a test set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-vb8yFOGRDF"
      },
      "source": [
        "## Implement context-sensitive spelling correction\n",
        "\n",
        "Your task is to implement context-sensitive spelling corrector using N-gram language model. The idea is to compute conditional probabilities of possible correction options. For example, the phrase \"dking sport\" should be fixed as \"doing sport\" not \"dying sport\", while \"dking species\" -- as \"dying species\".\n",
        "\n",
        "The best way to start is to analyze [Norvig's solution](https://norvig.com/spell-correct.html) and [N-gram Language Models](https://web.stanford.edu/~jurafsky/slp3/3.pdf).\n",
        "\n",
        "You may also want to implement:\n",
        "- spell-checking for a concrete language - Russian, Tatar, etc. - any one you know, such that the solution accounts for language specifics,\n",
        "- some recent (or not very recent) paper on this topic,\n",
        "- solution which takes into account keyboard layout and associated misspellings,\n",
        "- efficiency improvement to make the solution faster,\n",
        "- any other idea of yours to improve the Norvig’s solution.\n",
        "\n",
        "IMPORTANT:  \n",
        "Your project should not be a mere code copy-paste from somewhere. You must provide:\n",
        "- Your implementation\n",
        "- Analysis of why the implemented approach is suggested\n",
        "- Improvements of the original approach that you have chosen to implement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Solution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation of the spelling corrector using N-gram language model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "import string\n",
        "import itertools\n",
        "import random\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "random.seed(22)\n",
        "\n",
        "ALPHABET = string.ascii_lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model:\n",
        "    \"\"\"\n",
        "    Class for n-gram language model\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, order: int, smoothing: float = 0.001, weights: dict[int, float] = {-1: 0.001, 1: 0.9, 2: 0.099}):\n",
        "        self.order = order\n",
        "        self.smoothing = smoothing\n",
        "        self.weights = weights\n",
        "        self.n_grams_vocab = {}\n",
        "        self.vocab = set()\n",
        "\n",
        "    def known(self, words: list[str]):\n",
        "        \"\"\"\n",
        "        Returns the subset of `words` that are in the vocabulary\n",
        "        \"\"\"\n",
        "        return set(word for word in words if word in self.vocab)\n",
        "\n",
        "    def ngrams(self, text: list[str]):\n",
        "        \"\"\"\n",
        "        Generates n-grams from `text`\n",
        "        \"\"\"\n",
        "        return [\n",
        "            tuple(text[i: i + self.order]) for i in range(len(text) - self.order + 1)\n",
        "        ]\n",
        "\n",
        "    def train_model(self, corpus: str):\n",
        "        \"\"\"\n",
        "        Trains model on a `corpus`\n",
        "        \"\"\"\n",
        "        split = corpus.split()\n",
        "        self.vocab = set(split)\n",
        "        ngram_counts = Counter(self.ngrams(split))\n",
        "        total_counts = sum(ngram_counts.values())\n",
        "        self.n_grams_vocab = {\n",
        "            ngram: count / total_counts\n",
        "            for ngram, count in ngram_counts.items()\n",
        "        }\n",
        "\n",
        "    def train_from_ngrams(self, ngram_counts: dict[tuple[str], int], total_counts: int):\n",
        "        \"\"\"\n",
        "        Trains model from a precomputed n-gram counts\n",
        "        \"\"\"\n",
        "        self.n_grams_vocab = {\n",
        "            ngram: count / total_counts\n",
        "            for ngram, count in ngram_counts.items()\n",
        "        }\n",
        "        self.vocab = set([word for ngram in ngram_counts.keys()\n",
        "                         for word in ngram])\n",
        "\n",
        "    def calculate_probability(self, sequence: str):\n",
        "        \"\"\"\n",
        "        Calculates the probability of a `sequence`\n",
        "        \"\"\"\n",
        "        probability = 1.0\n",
        "        for i in range(len(sequence) - 1):\n",
        "            ngram = tuple(sequence[i: i + self.order])\n",
        "            if ngram in self.n_grams_vocab:\n",
        "                probability *= self.n_grams_vocab[ngram]\n",
        "            else:\n",
        "                # Apply smoothing if ngram not found\n",
        "                probability *= self.smoothing\n",
        "\n",
        "        return probability\n",
        "\n",
        "    def edits(self, word: str):\n",
        "        \"\"\"\n",
        "        Generate all edits that are one edit away from `word`\n",
        "        Taken from Peter Norvig's spell checker: https://norvig.com/spell-correct.html\n",
        "        \"\"\"\n",
        "        splits = [\n",
        "            (word[:i], word[i:])\n",
        "            for i in range(len(word) + 1)\n",
        "        ]\n",
        "        deletes = [\n",
        "            left + right[1:]\n",
        "            for left, right in splits if right\n",
        "        ]\n",
        "        inserts = [\n",
        "            left + c + right\n",
        "            for left, right in splits\n",
        "            for c in ALPHABET\n",
        "        ]\n",
        "        substitutions = [\n",
        "            left + c + right[1:]\n",
        "            for left, right in splits\n",
        "            for c in ALPHABET if right\n",
        "        ]\n",
        "        transposes = [\n",
        "            left + right[1] + right[0] + right[2:]\n",
        "            for left, right in splits if len(right) > 1\n",
        "        ]\n",
        "\n",
        "        return set(deletes + inserts + substitutions + transposes)\n",
        "\n",
        "    def edits2(self, word: str):\n",
        "        \"\"\"\n",
        "        Generate all edits that are two edits away from `word`\n",
        "        \"\"\"\n",
        "        return set(e2 for e1 in self.edits(word) for e2 in self.edits(e1))\n",
        "\n",
        "    def generate_corrections(self, word: str):\n",
        "        \"\"\"\n",
        "        Generates possible corrections for a misspelled `word`\n",
        "        \"\"\"\n",
        "        if word in self.vocab:\n",
        "            return word\n",
        "\n",
        "        # All 1-step edits from the original word\n",
        "        edits1 = self.edits(word)\n",
        "\n",
        "        # All 2-step edits from the original word\n",
        "        edits2 = self.edits2(word)\n",
        "\n",
        "        # If no known edits, return the original word\n",
        "        original = set([word])\n",
        "\n",
        "        return {\n",
        "            -1: original,\n",
        "            1: self.known(edits1),\n",
        "            2: self.known(edits2),\n",
        "        }\n",
        "\n",
        "    def context_correct(self, word: str, context: list[str]):\n",
        "        \"\"\"\n",
        "        Suggests context-sensitive correction for a `word` given a `context`\n",
        "        \"\"\"\n",
        "        best_correction, best_prob = None, 0\n",
        "\n",
        "        probs = {}\n",
        "\n",
        "        corrections = self.generate_corrections(word)\n",
        "        if type(corrections) == str:\n",
        "            return corrections, {corrections: 1}\n",
        "\n",
        "        for candidate in corrections[-1].union(corrections[1]).union(corrections[2]):\n",
        "            weights = self.weights[list(\n",
        "                filter(lambda x: candidate in corrections[x], [-1, 1, 2]))[0]]\n",
        "            candidate_best_prob = 0\n",
        "            for context_with_word in itertools.permutations(context + [candidate]):\n",
        "                context_prob = self.calculate_probability(\n",
        "                    context_with_word) * weights\n",
        "\n",
        "                if context_prob > best_prob:\n",
        "                    best_correction, best_prob = candidate, context_prob\n",
        "                if context_prob > candidate_best_prob:\n",
        "                    candidate_best_prob = context_prob\n",
        "\n",
        "            probs[candidate] = candidate_best_prob\n",
        "\n",
        "        return best_correction, probs\n",
        "\n",
        "    def correct_with_probs_print(self, word: str, context: list[str]):\n",
        "        \"\"\"\n",
        "        Suggests context-sensitive correction for a `word` given a `context` and prints the probabilities\n",
        "        \"\"\"\n",
        "        correction, probs = self.context_correct(word, context)\n",
        "        print(f\"Word: {word}\")\n",
        "        print(f\"Context: {' '.join(context)}\")\n",
        "        print(\"Probabilities:\")\n",
        "        for candidate, prob in probs.items():\n",
        "            print(f\"  {candidate}: {prob}\")\n",
        "        print(f\"Correction: {correction}\")\n",
        "        print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Testing different n-gram models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = \"sad species dying queen king kingdom sport strength doing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: dking\n",
            "Context: species\n",
            "Probabilities:\n",
            "  dking: 0.0001111111111111111\n",
            "  dying: 0.09999999999999999\n",
            "  king: 0.09999999999999999\n",
            "  doing: 0.09999999999999999\n",
            "Correction: dying\n",
            "\n",
            "\n",
            "Word: dking\n",
            "Context: kingdom\n",
            "Probabilities:\n",
            "  dking: 0.0001111111111111111\n",
            "  dying: 0.09999999999999999\n",
            "  king: 0.09999999999999999\n",
            "  doing: 0.09999999999999999\n",
            "Correction: dying\n",
            "\n",
            "\n",
            "Word: dking\n",
            "Context: sport\n",
            "Probabilities:\n",
            "  dking: 0.0001111111111111111\n",
            "  dying: 0.09999999999999999\n",
            "  king: 0.09999999999999999\n",
            "  doing: 0.09999999999999999\n",
            "Correction: dying\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "unigram_model = Model(order=1)\n",
        "unigram_model.train_model(corpus)\n",
        "\n",
        "unigram_model.correct_with_probs_print(\"dking\", [\"species\"])\n",
        "unigram_model.correct_with_probs_print(\"dking\", [\"kingdom\"])\n",
        "unigram_model.correct_with_probs_print(\"dking\", [\"sport\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: dking\n",
            "Context: species\n",
            "Probabilities:\n",
            "  dking: 1e-06\n",
            "  dying: 0.1125\n",
            "  king: 0.0009000000000000001\n",
            "  doing: 0.0009000000000000001\n",
            "Correction: dying\n",
            "\n",
            "\n",
            "Word: dking\n",
            "Context: kingdom\n",
            "Probabilities:\n",
            "  dking: 1e-06\n",
            "  dying: 0.0009000000000000001\n",
            "  king: 0.1125\n",
            "  doing: 0.0009000000000000001\n",
            "Correction: king\n",
            "\n",
            "\n",
            "Word: dking\n",
            "Context: sport\n",
            "Probabilities:\n",
            "  dking: 1e-06\n",
            "  dying: 0.0009000000000000001\n",
            "  king: 0.0009000000000000001\n",
            "  doing: 0.0009000000000000001\n",
            "Correction: dying\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "bigram_model = Model(order=2)\n",
        "bigram_model.train_model(corpus)\n",
        "\n",
        "bigram_model.correct_with_probs_print(\"dking\", [\"species\"])\n",
        "bigram_model.correct_with_probs_print(\"dking\", [\"kingdom\"])\n",
        "bigram_model.correct_with_probs_print(\"dking\", [\"sport\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word: dking\n",
            "Context: species sad\n",
            "Probabilities:\n",
            "  dking: 1e-09\n",
            "  dying: 0.00012857142857142855\n",
            "  king: 9e-07\n",
            "  doing: 9e-07\n",
            "Correction: dying\n",
            "\n",
            "\n",
            "Word: dking\n",
            "Context: kingdom queen\n",
            "Probabilities:\n",
            "  dking: 1e-09\n",
            "  dying: 9e-07\n",
            "  king: 0.00012857142857142855\n",
            "  doing: 9e-07\n",
            "Correction: king\n",
            "\n",
            "\n",
            "Word: dking\n",
            "Context: sport strength\n",
            "Probabilities:\n",
            "  dking: 1e-09\n",
            "  dying: 9e-07\n",
            "  king: 9e-07\n",
            "  doing: 0.00012857142857142855\n",
            "Correction: doing\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trigram_model = Model(order=3)\n",
        "trigram_model.train_model(corpus)\n",
        "\n",
        "trigram_model.correct_with_probs_print(\"dking\", [\"species\", \"sad\"])\n",
        "trigram_model.correct_with_probs_print(\"dking\", [\"kingdom\", \"queen\"])\n",
        "trigram_model.correct_with_probs_print(\"dking\", [\"sport\", \"strength\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Justification of the decisions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Which n-gram model to use?\n",
        "\n",
        "For the spelling correction task, we need to choose the n-gram model that best captures the context of the words. The context of the words is important for the spelling correction task, because the correct spelling of a word depends on the words that come before and after it. For example, in the phrase \"dking sport\", the correct spelling of \"dking\" depends on the word \"sport\" that comes after it. \n",
        "\n",
        "With larger n-gram models, we may not have enough data to estimate the probabilities of the n-grams, and the model may become too sparse. On the other hand, with smaller n-gram models, we may not capture enough context to make accurate corrections.\n",
        "\n",
        "I will choose the 2-gram model, because it captures enough context to make accurate corrections, and it is not too sparse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Which weights to assign for edit1, edit2 or absent words probabilities\n",
        "\n",
        "For the spelling correction task, we need to assign weights to the probabilities of the edit1, edit2 and absent words. The weights should be chosen such that they reflect the likelihood of each type of error.\n",
        "\n",
        "I decided to assign the following weights:\n",
        "- word already in the vocabulary: 1 (if word already in the vocabulary - it is the most likely already correct word)\n",
        "- edit1: 0.8 (one mistake is possible, so I gave it a high probability)\n",
        "- edit2: 0.199 (two mistakes are less likely than one mistake, so I gave it a lower probability)\n",
        "- no edits: 0.001 (almost impossible to have a word that is not in the vocabulary and has no mistakes, but I still gave it a small probability if no other options are available)\n",
        "\n",
        "Also for checking the probability of n-grams I used smoothing with factor 0.001 to avoid zero probabilities (it is possible that some n-grams are not in the training data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46rk65S4GRSe"
      },
      "source": [
        "## Evaluate on a test set\n",
        "\n",
        "Your task is to generate a test set and evaluate your work. You may vary the noise probability to generate different datasets with varying compexity. Compare your solution to the Norvig's corrector, and report the accuracies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "def read_ngrams(file: str):\n",
        "    with open(file, \"r\") as f:\n",
        "        ngram_counts = {}\n",
        "        for line in f:\n",
        "            split = line.split(\"\\t\")\n",
        "            count = int(split[0])\n",
        "            ngram = tuple(split[1:])\n",
        "            ngram_counts[ngram] = count\n",
        "\n",
        "    return ngram_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "def misspell_word(word: str):\n",
        "    \"\"\"\n",
        "    Misspells a word by randomly changing a character\n",
        "    \"\"\"\n",
        "    mode = random.randint(2 if len(word) == 1 else 0, 4)\n",
        "\n",
        "    if mode == 0:\n",
        "        # Randomly delete a character\n",
        "        idx = random.randint(0, len(word) - 1)\n",
        "        return word[:idx] + word[idx + 1:]\n",
        "\n",
        "    if mode == 1:\n",
        "        # Randomly transpose two characters\n",
        "        idx = random.randint(0, len(word) - 2)\n",
        "        return word[:idx] + word[idx + 1] + word[idx] + word[idx + 2:]\n",
        "\n",
        "    if mode == 2:\n",
        "        # Randomly insert a character\n",
        "        idx = random.randint(0, len(word))\n",
        "        return word[:idx] + random.choice(ALPHABET) + word[idx:]\n",
        "\n",
        "    if mode == 3:\n",
        "        # Randomly change a character\n",
        "        idx = random.randint(0, len(word) - 1)\n",
        "        return word[:idx] + random.choice(ALPHABET) + word[idx + 1:]\n",
        "\n",
        "    if mode == 4:\n",
        "        # Randomly change a character to a random character\n",
        "        idx = random.randint(0, len(word) - 1)\n",
        "        return word[:idx] + random.choice(ALPHABET) + word[idx + 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 187,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "class NorvigModel:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.WORDS = Counter(self.words(open('bigrams.txt').read()))\n",
        "\n",
        "    def context_correct(self, word: str, _: list[str]):\n",
        "        \"\"\"\n",
        "        This function is not implemented in the Norvig model, but I added it to make the interface consistent\n",
        "        \"\"\"\n",
        "        return self.correction(word), {}\n",
        "\n",
        "\n",
        "    def words(self, text):\n",
        "\n",
        "        return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "\n",
        "    def P(self, word):\n",
        "\n",
        "        \"Probability of `word`.\"\n",
        "\n",
        "        return self.WORDS[word] / sum(self.WORDS.values())\n",
        "\n",
        "\n",
        "    def correction(self, word):\n",
        "\n",
        "        \"Most probable spelling correction for word.\"\n",
        "\n",
        "        return max(self.candidates(word), key=self.P)\n",
        "\n",
        "\n",
        "    def candidates(self, word):\n",
        "\n",
        "        \"Generate possible spelling corrections for word.\"\n",
        "\n",
        "        return (self.known([word]) or self.known(self.edits1(word)) or self.known(self.edits2(word)) or [word])\n",
        "\n",
        "\n",
        "    def known(self, words):\n",
        "\n",
        "        \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "\n",
        "        return set(w for w in words if w in self.WORDS)\n",
        "\n",
        "\n",
        "    def edits1(self, word):\n",
        "\n",
        "        \"All edits that are one edit away from `word`.\"\n",
        "\n",
        "        letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "        splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
        "\n",
        "        deletes = [L + R[1:] for L, R in splits if R]\n",
        "\n",
        "        transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R) > 1]\n",
        "\n",
        "        replaces = [L + c + R[1:] for L, R in splits if R for c in letters]\n",
        "\n",
        "        inserts = [L + c + R for L, R in splits for c in letters]\n",
        "\n",
        "        return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "\n",
        "    def edits2(self, word):\n",
        "\n",
        "        \"All edits that are two edits away from `word`.\"\n",
        "\n",
        "        return (e2 for e1 in self.edits1(word) for e2 in self.edits1(e1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 188,
      "metadata": {
        "id": "OwZWaX9VVs7B"
      },
      "outputs": [],
      "source": [
        "bigrams = read_ngrams(\"bigrams.txt\")\n",
        "fivegrams = read_ngrams(\"fivegrams.txt\")\n",
        "\n",
        "bigram_model = Model(order=2)\n",
        "bigram_model.train_from_ngrams(bigrams, sum(bigrams.values()))\n",
        "\n",
        "fivegram_model = Model(order=5)\n",
        "fivegram_model.train_from_ngrams(fivegrams, sum(fivegrams.values()))\n",
        "\n",
        "norvig_model = NorvigModel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the evaluation, I will use the Large Movie Review Dataset (https://ai.stanford.edu/~amaas/data/sentiment/) as a test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'I know John Singleton\\'s a smart guy \\'coz he made Boyz N The Hood, so how did he write and direct this? It\\'s like the pilot of a bad \"going away to college for the first time\" teen soap, a parade of boring stereotypes and cliches with some gratuitous violence thrown in to make it a commercial proposition, I guess. Who would\\'ve guessed the date-rape victim would dump sausage for seafood? The angry loner would be preyed upon by a group of Neo-Nazis (and would be roomed-up with a black AND a Jew - just for laughs!) Even Laurence Fishburne\\'s creepy reactionary history Professor just irritated me and I love the guy, it\\'s like everyone involved with this movie just lost the plot. Except Busta Rhymes, of course. Big ups.'"
            ]
          },
          "execution_count": 261,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imdb = pd.read_csv(\"imdb.csv\").dropna().sample(\n",
        "    100, random_state=22)[\"review\"].values.tolist()\n",
        "imdb[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate_model(model, data):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for review in tqdm(data):\n",
        "        words = review.split()\n",
        "        # remove punctuation and lowercase\n",
        "        words = [\n",
        "            word.translate(str.maketrans(\"\", \"\", string.punctuation)).lower()\n",
        "            for word in words\n",
        "        ]\n",
        "        words = [word for word in words if word]\n",
        "\n",
        "        random_word_idx = random.randint(0, len(words) - 1)\n",
        "        while len(words[random_word_idx]) < 5:\n",
        "            random_word_idx = random.randint(0, len(words) - 1)\n",
        "        word = words[random_word_idx]\n",
        "        context = (\n",
        "            words[max(0, random_word_idx - 2): random_word_idx]\n",
        "            + words[random_word_idx + 1: min(len(words), random_word_idx + 2)]\n",
        "        )\n",
        "        misspelled_word = misspell_word(word)\n",
        "\n",
        "        correction, _ = model.context_correct(misspelled_word, context)\n",
        "        if correction == word:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "\n",
        "    return correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:10<00:00,  9.55it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model(bigram_model, imdb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:08<00:00, 11.49it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "execution_count": 293,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model(fivegram_model, imdb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 302,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:01<00:00, 54.27it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.72"
            ]
          },
          "execution_count": 302,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate_model(norvig_model, imdb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "My model performance is slightly better than Norvig's corrector. In my opinion, it can be even better, but dataset is not very high quality for checking the accuracy of the model, since even in the original reviews there may be errors (that is, in the context) and the model may not be able to correct them accurately."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example where context model is better than the Norvig's corrector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I want to correct `holme in door` to `home in door`. The Norvig's corrector will correct `holme` to `home`, which is not correct. The context model is able to correct this mistake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 303,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'home'"
            ]
          },
          "execution_count": 303,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "norvig_model.correction(\"holme\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 304,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'hole'"
            ]
          },
          "execution_count": 304,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bigram_model.context_correct(\"holme\", [\"in\", \"door\"])[0]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
